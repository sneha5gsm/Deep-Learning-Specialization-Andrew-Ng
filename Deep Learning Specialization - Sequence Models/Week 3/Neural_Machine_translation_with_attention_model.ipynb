{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Bidirectional, Concatenate, Permute, Dot, Input, LSTM, Multiply\n",
    "from keras.layers import RepeatVector, Dense, Activation, Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model, Model\n",
    "import keras.backend as K\n",
    "import numpy as np\n",
    "\n",
    "from faker import Faker\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "from babel.dates import format_date\n",
    "from nmt_utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting faker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x000001CBF554FF48>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))': /simple/faker/\n",
      "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x000001CBF554FBC8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))': /simple/faker/\n",
      "  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x000001CBF5546548>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))': /simple/faker/\n",
      "  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x000001CBF55468C8>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))': /simple/faker/\n",
      "  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProxyError('Cannot connect to proxy.', NewConnectionError('<pip._vendor.urllib3.connection.VerifiedHTTPSConnection object at 0x000001CBF5546148>: Failed to establish a new connection: [Errno 11001] getaddrinfo failed'))': /simple/faker/\n",
      "  ERROR: Could not find a version that satisfies the requirement faker (from versions: none)\n",
      "ERROR: No matching distribution found for faker\n"
     ]
    }
   ],
   "source": [
    "!$env:HTTP_PROXY=\"\"\n",
    "!$env:HTTPS_PROXY=\"\"\n",
    "!pip install faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 10000/10000 [00:00<00:00, 13660.33it/s]\n"
     ]
    }
   ],
   "source": [
    "m = 10000\n",
    "dataset, human_vocab, machine_vocab, inv_machine_vocab = load_dataset(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('9 may 1998', '1998-05-09'),\n",
       " ('10.11.19', '2019-11-10'),\n",
       " ('9/10/70', '1970-09-10'),\n",
       " ('saturday april 28 1990', '1990-04-28'),\n",
       " ('thursday january 26 1995', '1995-01-26'),\n",
       " ('monday march 7 1983', '1983-03-07'),\n",
       " ('sunday may 22 1988', '1988-05-22'),\n",
       " ('08 jul 2008', '2008-07-08'),\n",
       " ('8 sep 1999', '1999-09-08'),\n",
       " ('thursday january 1 1981', '1981-01-01')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape: (10000, 30)\n",
      "Y.shape: (10000, 10)\n",
      "Xoh.shape: (10000, 30, 37)\n",
      "Yoh.shape: (10000, 10, 11)\n"
     ]
    }
   ],
   "source": [
    "Tx = 30\n",
    "Ty = 10\n",
    "X, Y, Xoh, Yoh = preprocess_data(dataset, human_vocab, machine_vocab, Tx, Ty)\n",
    "\n",
    "print(\"X.shape:\", X.shape)\n",
    "print(\"Y.shape:\", Y.shape)\n",
    "print(\"Xoh.shape:\", Xoh.shape)\n",
    "print(\"Yoh.shape:\", Yoh.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{' ': 0, '.': 1, '/': 2, '0': 3, '1': 4, '2': 5, '3': 6, '4': 7, '5': 8, '6': 9, '7': 10, '8': 11, '9': 12, 'a': 13, 'b': 14, 'c': 15, 'd': 16, 'e': 17, 'f': 18, 'g': 19, 'h': 20, 'i': 21, 'j': 22, 'l': 23, 'm': 24, 'n': 25, 'o': 26, 'p': 27, 'r': 28, 's': 29, 't': 30, 'u': 31, 'v': 32, 'w': 33, 'y': 34, '<unk>': 35, '<pad>': 36}\n"
     ]
    }
   ],
   "source": [
    "print(human_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'-': 0, '0': 1, '1': 2, '2': 3, '3': 4, '4': 5, '5': 6, '6': 7, '7': 8, '8': 9, '9': 10}\n"
     ]
    }
   ],
   "source": [
    "print(machine_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      "  36 36 36 36 36 36]\n",
      " [ 4  3  1  4  4  1  4 12 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      "  36 36 36 36 36 36]\n",
      " [12  2  4  3  2 10  3 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      "  36 36 36 36 36 36]\n",
      " [29 13 30 31 28 16 13 34  0 13 27 28 21 23  0  5 11  0  4 12 12  3 36 36\n",
      "  36 36 36 36 36 36]\n",
      " [30 20 31 28 29 16 13 34  0 22 13 25 31 13 28 34  0  5  9  0  4 12 12  8\n",
      "  36 36 36 36 36 36]]\n"
     ]
    }
   ],
   "source": [
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source date: 9 may 1998\n",
      "Target date: 1998-05-09\n",
      "\n",
      "Source after preprocessing (indices): [12  0 24 13 34  0  4 12 12 11 36 36 36 36 36 36 36 36 36 36 36 36 36 36\n",
      " 36 36 36 36 36 36]\n",
      "Target after preprocessing (indices): [ 2 10 10  9  0  1  6  0  1 10]\n",
      "\n",
      "Source after preprocessing (one-hot): [[0. 0. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]]\n",
      "Target after preprocessing (one-hot): [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "index = 0\n",
    "print(\"Source date:\", dataset[index][0])\n",
    "print(\"Target date:\", dataset[index][1])\n",
    "print()\n",
    "print(\"Source after preprocessing (indices):\", X[index])\n",
    "print(\"Target after preprocessing (indices):\", Y[index])\n",
    "print()\n",
    "print(\"Source after preprocessing (one-hot):\", Xoh[index])\n",
    "print(\"Target after preprocessing (one-hot):\", Yoh[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "## 2 - Neural machine translation with attention\n",
       "\n",
       "* If you had to translate a book's paragraph from French to English, you would not read the whole paragraph, then close the book and translate. \n",
       "* Even during the translation process, you would read/re-read and focus on the parts of the French paragraph corresponding to the parts of the English you are writing down. \n",
       "* The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. \n",
       "\n",
       "\n",
       "### 2.1 - Attention mechanism\n",
       "\n",
       "In this part, you will implement the attention mechanism presented in the lecture videos. \n",
       "* Here is a figure to remind you how the model works. \n",
       "    * The diagram on the left shows the attention model. \n",
       "    * The diagram on the right shows what one \"attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$.\n",
       "    * The attention variables $\\alpha^{\\langle t, t' \\rangle}$ are used to compute the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$). \n",
       "\n",
       "<table>\n",
       "<td> \n",
       "<img src=\"attn_model.png\" style=\"width:500;height:500px;\"> <br>\n",
       "</td> \n",
       "<td> \n",
       "<img src=\"attn_mechanism.png\" style=\"width:500;height:500px;\"> <br>\n",
       "</td> \n",
       "</table>\n",
       "<caption><center> **Figure 1**: Neural machine translation with attention</center></caption>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "## 2 - Neural machine translation with attention\n",
    "\n",
    "* If you had to translate a book's paragraph from French to English, you would not read the whole paragraph, then close the book and translate. \n",
    "* Even during the translation process, you would read/re-read and focus on the parts of the French paragraph corresponding to the parts of the English you are writing down. \n",
    "* The attention mechanism tells a Neural Machine Translation model where it should pay attention to at any step. \n",
    "\n",
    "\n",
    "### 2.1 - Attention mechanism\n",
    "\n",
    "In this part, you will implement the attention mechanism presented in the lecture videos. \n",
    "* Here is a figure to remind you how the model works. \n",
    "    * The diagram on the left shows the attention model. \n",
    "    * The diagram on the right shows what one \"attention\" step does to calculate the attention variables $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "    * The attention variables $\\alpha^{\\langle t, t' \\rangle}$ are used to compute the context variable $context^{\\langle t \\rangle}$ for each timestep in the output ($t=1, \\ldots, T_y$). \n",
    "\n",
    "<table>\n",
    "<td> \n",
    "<img src=\"attn_model.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "<td> \n",
    "<img src=\"attn_mechanism.png\" style=\"width:500;height:500px;\"> <br>\n",
    "</td> \n",
    "</table>\n",
    "<caption><center> **Figure 1**: Neural machine translation with attention</center></caption>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Here are some properties of the model that you may notice: \n",
       "\n",
       "#### Pre-attention and Post-attention LSTMs on both sides of the attention mechanism\n",
       "- There are two separate LSTMs in this model (see diagram on the left): pre-attention and post-attention LSTMs.\n",
       "- *Pre-attention* Bi-LSTM is the one at the bottom of the picture is a Bi-directional LSTM and comes *before* the attention mechanism.\n",
       "    - The attention mechanism is shown in the middle of the left-hand diagram.\n",
       "    - The pre-attention Bi-LSTM goes through $T_x$ time steps\n",
       "- *Post-attention* LSTM: at the top of the diagram comes *after* the attention mechanism. \n",
       "    - The post-attention LSTM goes through $T_y$ time steps. \n",
       "\n",
       "- The post-attention LSTM passes the hidden state $s^{\\langle t \\rangle}$ and cell state $c^{\\langle t \\rangle}$ from one time step to the next. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "Here are some properties of the model that you may notice: \n",
    "\n",
    "#### Pre-attention and Post-attention LSTMs on both sides of the attention mechanism\n",
    "- There are two separate LSTMs in this model (see diagram on the left): pre-attention and post-attention LSTMs.\n",
    "- *Pre-attention* Bi-LSTM is the one at the bottom of the picture is a Bi-directional LSTM and comes *before* the attention mechanism.\n",
    "    - The attention mechanism is shown in the middle of the left-hand diagram.\n",
    "    - The pre-attention Bi-LSTM goes through $T_x$ time steps\n",
    "- *Post-attention* LSTM: at the top of the diagram comes *after* the attention mechanism. \n",
    "    - The post-attention LSTM goes through $T_y$ time steps. \n",
    "\n",
    "- The post-attention LSTM passes the hidden state $s^{\\langle t \\rangle}$ and cell state $c^{\\langle t \\rangle}$ from one time step to the next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "#### An LSTM has both a hidden state and cell state\n",
       "* In the lecture videos, we were using only a basic RNN for the post-attention sequence model\n",
       "    * This means that the state captured by the RNN was outputting only the hidden state $s^{\\langle t\\rangle}$. \n",
       "* In this assignment, we are using an LSTM instead of a basic RNN.\n",
       "    * So the LSTM has both the hidden state $s^{\\langle t\\rangle}$ and the cell state $c^{\\langle t\\rangle}$. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "#### An LSTM has both a hidden state and cell state\n",
    "* In the lecture videos, we were using only a basic RNN for the post-attention sequence model\n",
    "    * This means that the state captured by the RNN was outputting only the hidden state $s^{\\langle t\\rangle}$. \n",
    "* In this assignment, we are using an LSTM instead of a basic RNN.\n",
    "    * So the LSTM has both the hidden state $s^{\\langle t\\rangle}$ and the cell state $c^{\\langle t\\rangle}$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "#### Each time step does not use predictions from the previous time step\n",
       "* Unlike previous text generation examples earlier in the course, in this model, the post-attention LSTM at time $t$ does not take the previous time step's prediction $y^{\\langle t-1 \\rangle}$ as input.\n",
       "* The post-attention LSTM at time 't' only takes the hidden state $s^{\\langle t\\rangle}$ and cell state $c^{\\langle t\\rangle}$ as input. \n",
       "* We have designed the model this way because unlike language generation (where adjacent characters are highly correlated) there isn't as strong a dependency between the previous character and the next character in a YYYY-MM-DD date.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "#### Each time step does not use predictions from the previous time step\n",
    "* Unlike previous text generation examples earlier in the course, in this model, the post-attention LSTM at time $t$ does not take the previous time step's prediction $y^{\\langle t-1 \\rangle}$ as input.\n",
    "* The post-attention LSTM at time 't' only takes the hidden state $s^{\\langle t\\rangle}$ and cell state $c^{\\langle t\\rangle}$ as input. \n",
    "* We have designed the model this way because unlike language generation (where adjacent characters are highly correlated) there isn't as strong a dependency between the previous character and the next character in a YYYY-MM-DD date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "#### Concatenation of hidden states from the forward and backward pre-attention LSTMs\n",
       "- $\\overrightarrow{a}^{\\langle t \\rangle}$: hidden state of the forward-direction, pre-attention LSTM.\n",
       "- $\\overleftarrow{a}^{\\langle t \\rangle}$: hidden state of the backward-direction, pre-attention LSTM.\n",
       "- $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}, \\overleftarrow{a}^{\\langle t \\rangle}]$: the concatenation of the activations of both the forward-direction $\\overrightarrow{a}^{\\langle t \\rangle}$ and backward-directions $\\overleftarrow{a}^{\\langle t \\rangle}$ of the pre-attention Bi-LSTM. \n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "#### Concatenation of hidden states from the forward and backward pre-attention LSTMs\n",
    "- $\\overrightarrow{a}^{\\langle t \\rangle}$: hidden state of the forward-direction, pre-attention LSTM.\n",
    "- $\\overleftarrow{a}^{\\langle t \\rangle}$: hidden state of the backward-direction, pre-attention LSTM.\n",
    "- $a^{\\langle t \\rangle} = [\\overrightarrow{a}^{\\langle t \\rangle}, \\overleftarrow{a}^{\\langle t \\rangle}]$: the concatenation of the activations of both the forward-direction $\\overrightarrow{a}^{\\langle t \\rangle}$ and backward-directions $\\overleftarrow{a}^{\\langle t \\rangle}$ of the pre-attention Bi-LSTM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "#### Computing \"energies\" $e^{\\langle t, t' \\rangle}$ as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$\n",
       "- Recall in the lesson videos \"Attention Model\", at time 6:45 to 8:16, the definition of \"e\" as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$.\n",
       "    - \"e\" is called the \"energies\" variable.\n",
       "    - $s^{\\langle t-1 \\rangle}$ is the hidden state of the post-attention LSTM\n",
       "    - $a^{\\langle t' \\rangle}$ is the hidden state of the pre-attention LSTM.\n",
       "    - $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ are fed into a simple neural network, which learns the function to output $e^{\\langle t, t' \\rangle}$.\n",
       "    - $e^{\\langle t, t' \\rangle}$ is then used when computing the attention $a^{\\langle t, t' \\rangle}$ that $y^{\\langle t \\rangle}$ should pay to $a^{\\langle t' \\rangle}$.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "#### Computing \"energies\" $e^{\\langle t, t' \\rangle}$ as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t' \\rangle}$\n",
    "- Recall in the lesson videos \"Attention Model\", at time 6:45 to 8:16, the definition of \"e\" as a function of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$.\n",
    "    - \"e\" is called the \"energies\" variable.\n",
    "    - $s^{\\langle t-1 \\rangle}$ is the hidden state of the post-attention LSTM\n",
    "    - $a^{\\langle t' \\rangle}$ is the hidden state of the pre-attention LSTM.\n",
    "    - $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ are fed into a simple neural network, which learns the function to output $e^{\\langle t, t' \\rangle}$.\n",
    "    - $e^{\\langle t, t' \\rangle}$ is then used when computing the attention $a^{\\langle t, t' \\rangle}$ that $y^{\\langle t \\rangle}$ should pay to $a^{\\langle t' \\rangle}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "- The diagram on the right of figure 1 uses a `RepeatVector` node to copy $s^{\\langle t-1 \\rangle}$'s value $T_x$ times.\n",
       "- Then it uses `Concatenation` to concatenate $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$.\n",
       "- The concatenation of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ is fed into a \"Dense\" layer, which computes $e^{\\langle t, t' \\rangle}$. \n",
       "- $e^{\\langle t, t' \\rangle}$ is then passed through a softmax to compute $\\alpha^{\\langle t, t' \\rangle}$.\n",
       "- Note that the diagram doesn't explicitly show variable $e^{\\langle t, t' \\rangle}$, but $e^{\\langle t, t' \\rangle}$ is above the Dense layer and below the Softmax layer in the diagram in the right half of figure 1.\n",
       "- We'll explain how to use `RepeatVector` and `Concatenation` in Keras below. \n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "- The diagram on the right of figure 1 uses a `RepeatVector` node to copy $s^{\\langle t-1 \\rangle}$'s value $T_x$ times.\n",
    "- Then it uses `Concatenation` to concatenate $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$.\n",
    "- The concatenation of $s^{\\langle t-1 \\rangle}$ and $a^{\\langle t \\rangle}$ is fed into a \"Dense\" layer, which computes $e^{\\langle t, t' \\rangle}$. \n",
    "- $e^{\\langle t, t' \\rangle}$ is then passed through a softmax to compute $\\alpha^{\\langle t, t' \\rangle}$.\n",
    "- Note that the diagram doesn't explicitly show variable $e^{\\langle t, t' \\rangle}$, but $e^{\\langle t, t' \\rangle}$ is above the Dense layer and below the Softmax layer in the diagram in the right half of figure 1.\n",
    "- We'll explain how to use `RepeatVector` and `Concatenation` in Keras below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "### Implementation Details\n",
       "   \n",
       "Let's implement this neural translator. You will start by implementing two functions: `one_step_attention()` and `model()`.\n",
       "\n",
       "#### one_step_attention\n",
       "* The inputs to the one_step_attention at time step $t$ are:\n",
       "    - $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$: all hidden states of the pre-attention Bi-LSTM.\n",
       "    - $s^{<t-1>}$: the previous hidden state of the post-attention LSTM \n",
       "* one_step_attention computes:\n",
       "    - $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$: the attention weights\n",
       "    - $context^{ \\langle t \\rangle }$: the context vector:\n",
       "    \n",
       "$$context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n",
       "\n",
       "##### Clarifying 'context' and 'c'\n",
       "- In the lecture videos, the context was denoted $c^{\\langle t \\rangle}$\n",
       "- In the assignment, we are calling the context $context^{\\langle t \\rangle}$.\n",
       "    - This is to avoid confusion with the post-attention LSTM's internal memory cell variable, which is also denoted $c^{\\langle t \\rangle}$.\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "### Implementation Details\n",
    "   \n",
    "Let's implement this neural translator. You will start by implementing two functions: `one_step_attention()` and `model()`.\n",
    "\n",
    "#### one_step_attention\n",
    "* The inputs to the one_step_attention at time step $t$ are:\n",
    "    - $[a^{<1>},a^{<2>}, ..., a^{<T_x>}]$: all hidden states of the pre-attention Bi-LSTM.\n",
    "    - $s^{<t-1>}$: the previous hidden state of the post-attention LSTM \n",
    "* one_step_attention computes:\n",
    "    - $[\\alpha^{<t,1>},\\alpha^{<t,2>}, ..., \\alpha^{<t,T_x>}]$: the attention weights\n",
    "    - $context^{ \\langle t \\rangle }$: the context vector:\n",
    "    \n",
    "$$context^{<t>} = \\sum_{t' = 1}^{T_x} \\alpha^{<t,t'>}a^{<t'>}\\tag{1}$$ \n",
    "\n",
    "##### Clarifying 'context' and 'c'\n",
    "- In the lecture videos, the context was denoted $c^{\\langle t \\rangle}$\n",
    "- In the assignment, we are calling the context $context^{\\langle t \\rangle}$.\n",
    "    - This is to avoid confusion with the post-attention LSTM's internal memory cell variable, which is also denoted $c^{\\langle t \\rangle}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "#### Implement `one_step_attention`\n",
       "\n",
       "**Exercise**: Implement `one_step_attention()`. \n",
       "\n",
       "* The function `model()` will call the layers in `one_step_attention()` $T_y$ using a for-loop.\n",
       "* It is important that all $T_y$ copies have the same weights. \n",
       "    * It should not reinitialize the weights every time. \n",
       "    * In other words, all $T_y$ steps should have shared weights. \n",
       "* Here's how you can implement layers with shareable weights in Keras:\n",
       "    1. Define the layer objects in a variable scope that is outside of the `one_step_attention` function.  For example, defining the objects as global variables would work.\n",
       "        - Note that defining these variables inside the scope of the function `model` would technically work, since `model` will then call the `one_step_attention` function.  For the purposes of making grading and troubleshooting easier, we are defining these as global variables.  Note that the automatic grader will expect these to be global variables as well.\n",
       "    2. Call these objects when propagating the input.\n",
       "* We have defined the layers you need as global variables. \n",
       "    * Please run the following cells to create them. \n",
       "    * Please note that the automatic grader expects these global variables with the given variable names.  For grading purposes, please do not rename the global variables.\n",
       "* Please check the Keras documentation to learn more about these layers.  The layers are functions.  Below are examples of how to call these functions.\n",
       "    * [RepeatVector()](https://keras.io/layers/core/#repeatvector)\n",
       "```Python\n",
       "var_repeated = repeat_layer(var1)\n",
       "```\n",
       "    * [Concatenate()](https://keras.io/layers/merge/#concatenate)   \n",
       "```Python\n",
       "concatenated_vars = concatenate_layer([var1,var2,var3])\n",
       "```\n",
       "    * [Dense()](https://keras.io/layers/core/#dense)  \n",
       "```Python\n",
       "var_out = dense_layer(var_in)\n",
       "```\n",
       "    * [Activation()](https://keras.io/layers/core/#activation)  \n",
       "```Python\n",
       "activation = activation_layer(var_in)  \n",
       "```\n",
       "    * [Dot()](https://keras.io/layers/merge/#dot)  \n",
       "```Python\n",
       "dot_product = dot_layer([var1,var2])\n",
       "```\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "#### Implement `one_step_attention`\n",
    "\n",
    "**Exercise**: Implement `one_step_attention()`. \n",
    "\n",
    "* The function `model()` will call the layers in `one_step_attention()` $T_y$ using a for-loop.\n",
    "* It is important that all $T_y$ copies have the same weights. \n",
    "    * It should not reinitialize the weights every time. \n",
    "    * In other words, all $T_y$ steps should have shared weights. \n",
    "* Here's how you can implement layers with shareable weights in Keras:\n",
    "    1. Define the layer objects in a variable scope that is outside of the `one_step_attention` function.  For example, defining the objects as global variables would work.\n",
    "        - Note that defining these variables inside the scope of the function `model` would technically work, since `model` will then call the `one_step_attention` function.  For the purposes of making grading and troubleshooting easier, we are defining these as global variables.  Note that the automatic grader will expect these to be global variables as well.\n",
    "    2. Call these objects when propagating the input.\n",
    "* We have defined the layers you need as global variables. \n",
    "    * Please run the following cells to create them. \n",
    "    * Please note that the automatic grader expects these global variables with the given variable names.  For grading purposes, please do not rename the global variables.\n",
    "* Please check the Keras documentation to learn more about these layers.  The layers are functions.  Below are examples of how to call these functions.\n",
    "    * [RepeatVector()](https://keras.io/layers/core/#repeatvector)\n",
    "```Python\n",
    "var_repeated = repeat_layer(var1)\n",
    "```\n",
    "    * [Concatenate()](https://keras.io/layers/merge/#concatenate)   \n",
    "```Python\n",
    "concatenated_vars = concatenate_layer([var1,var2,var3])\n",
    "```\n",
    "    * [Dense()](https://keras.io/layers/core/#dense)  \n",
    "```Python\n",
    "var_out = dense_layer(var_in)\n",
    "```\n",
    "    * [Activation()](https://keras.io/layers/core/#activation)  \n",
    "```Python\n",
    "activation = activation_layer(var_in)  \n",
    "```\n",
    "    * [Dot()](https://keras.io/layers/merge/#dot)  \n",
    "```Python\n",
    "dot_product = dot_layer([var1,var2])\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined shared layers as global variables\n",
    "repeator = RepeatVector(Tx)\n",
    "concatenator = Concatenate(axis=-1)\n",
    "densor1 = Dense(10, activation = \"tanh\")\n",
    "densor2 = Dense(1, activation = \"relu\")\n",
    "activator = Activation(softmax, name='attention_weights') # We are using a custom softmax(axis = 1) loaded in this notebook\n",
    "dotor = Dot(axes = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: one_step_attention\n",
    "\n",
    "def one_step_attention(a, s_prev):\n",
    "    \"\"\"\n",
    "    Performs one step of attention: Outputs a context vector computed as a dot product of the attention weights\n",
    "    \"alphas\" and the hidden states \"a\" of the Bi-LSTM.\n",
    "    \n",
    "    Arguments:\n",
    "    a -- hidden state output of the Bi-LSTM, numpy-array of shape (m, Tx, 2*n_a)\n",
    "    s_prev -- previous hidden state of the (post-attention) LSTM, numpy-array of shape (m, n_s)\n",
    "    \n",
    "    Returns:\n",
    "    context -- context vector, input of the next (post-attention) LSTM cell\n",
    "    \"\"\"\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    # Use repeator to repeat s_prev to be of shape (m, Tx, n_s) so that you can concatenate it with all hidden states \"a\" (≈ 1 line)\n",
    "    s_prev = repeator(s_prev)\n",
    "    # Use concatenator to concatenate a and s_prev on the last axis (≈ 1 line)\n",
    "    # For grading purposes, please list 'a' first and 's_prev' second, in this order.\n",
    "    concat = concatenator([a, s_prev])\n",
    "    # Use densor1 to propagate concat through a small fully-connected neural network to compute the \"intermediate energies\" variable e. (≈1 lines)\n",
    "    e = densor1(concat)\n",
    "    # Use densor2 to propagate e through a small fully-connected neural network to compute the \"energies\" variable energies. (≈1 lines)\n",
    "    energies = densor2(e)\n",
    "    # Use \"activator\" on \"energies\" to compute the attention weights \"alphas\" (≈ 1 line)\n",
    "    alphas = activator(energies)\n",
    "    # Use dotor together with \"alphas\" and \"a\" to compute the context vector to be given to the next (post-attention) LSTM-cell (≈ 1 line)\n",
    "    context = dotor([alphas, a])\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_a = 32 # number of units for the pre-attention, bi-directional LSTM's hidden state 'a'\n",
    "n_s = 64 # number of units for the post-attention LSTM's hidden state \"s\"\n",
    "\n",
    "# Please note, this is the post attention LSTM cell.  \n",
    "# For the purposes of passing the automatic grader\n",
    "# please do not modify this global variable.  This will be corrected once the automatic grader is also updated.\n",
    "post_activation_LSTM_cell = LSTM(n_s, return_state = True) # post-attention LSTM \n",
    "output_layer = Dense(len(machine_vocab), activation=softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: model\n",
    "\n",
    "def model(Tx, Ty, n_a, n_s, human_vocab_size, machine_vocab_size):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "    Tx -- length of the input sequence\n",
    "    Ty -- length of the output sequence\n",
    "    n_a -- hidden state size of the Bi-LSTM\n",
    "    n_s -- hidden state size of the post-attention LSTM\n",
    "    human_vocab_size -- size of the python dictionary \"human_vocab\"\n",
    "    machine_vocab_size -- size of the python dictionary \"machine_vocab\"\n",
    "\n",
    "    Returns:\n",
    "    model -- Keras model instance\n",
    "    \"\"\"\n",
    "    \n",
    "    # Define the inputs of your model with a shape (Tx,)\n",
    "    # Define s0 (initial hidden state) and c0 (initial cell state)\n",
    "    # for the decoder LSTM with shape (n_s,)\n",
    "    X = Input(shape=(Tx, human_vocab_size))\n",
    "    s0 = Input(shape=(n_s,), name='s0')\n",
    "    c0 = Input(shape=(n_s,), name='c0')\n",
    "    s = s0\n",
    "    c = c0\n",
    "    \n",
    "    # Initialize empty list of outputs\n",
    "    outputs = []\n",
    "    \n",
    "    ### START CODE HERE ###\n",
    "    \n",
    "    # Step 1: Define your pre-attention Bi-LSTM. (≈ 1 line)\n",
    "    a = Bidirectional(LSTM(units=n_a, return_sequences=True))(X)\n",
    "    \n",
    "    # Step 2: Iterate for Ty steps\n",
    "    for t in range(Ty):\n",
    "    \n",
    "        # Step 2.A: Perform one step of the attention mechanism to get back the context vector at step t (≈ 1 line)\n",
    "        context = one_step_attention(a, s)\n",
    "        \n",
    "        # Step 2.B: Apply the post-attention LSTM cell to the \"context\" vector.\n",
    "        # Don't forget to pass: initial_state = [hidden state, cell state] (≈ 1 line)\n",
    "        s, _, c = post_activation_LSTM_cell(inputs=context, initial_state=[s, c])\n",
    "        \n",
    "        # Step 2.C: Apply Dense layer to the hidden state output of the post-attention LSTM (≈ 1 line)\n",
    "        out = output_layer(inputs=s)\n",
    "        \n",
    "        # Step 2.D: Append \"out\" to the \"outputs\" list (≈ 1 line)\n",
    "        outputs.append(out)\n",
    "    \n",
    "    # Step 3: Create model instance taking three inputs and returning the list of outputs. (≈ 1 line)\n",
    "    model = Model(inputs=[X, s0, c0], outputs=outputs)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model(Tx, Ty, n_a, n_s, len(human_vocab), len(machine_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 10)       1290        concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           715         lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "### START CODE HERE ### (≈2 lines)\n",
    "opt = Adam(lr=0.005, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = np.zeros((m, n_s))\n",
    "c0 = np.zeros((m, n_s))\n",
    "outputs = list(Yoh.swapaxes(0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "10000/10000 [==============================] - 12s 1ms/step - loss: 17.1111 - dense_3_loss: 2.5612 - dense_3_accuracy: 0.4317 - dense_3_accuracy_1: 0.6649 - dense_3_accuracy_2: 0.3026 - dense_3_accuracy_3: 0.0696 - dense_3_accuracy_4: 0.9224 - dense_3_accuracy_5: 0.3311 - dense_3_accuracy_6: 0.0370 - dense_3_accuracy_7: 0.9535 - dense_3_accuracy_8: 0.2282 - dense_3_accuracy_9: 0.1083\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x23ca6c39688>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([Xoh, s0, c0], outputs, epochs=1, batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('models/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected input_1 to have 3 dimensions, but got array with shape (37, 30)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0c135f5071a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstring_to_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhuman_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhuman_vocab\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mswapaxes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minv_machine_vocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\212601210\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1439\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1440\u001b[0m         \u001b[1;31m# Case 2: Symbolic tensors or Numpy array-like.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1441\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_standardize_user_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1442\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\212601210\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    577\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    580\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\212601210\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    133\u001b[0m                         \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m                         \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' dimensions, but got array '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m                         'with shape ' + str(data_shape))\n\u001b[0m\u001b[0;32m    136\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                     \u001b[0mdata_shape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_shape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected input_1 to have 3 dimensions, but got array with shape (37, 30)"
     ]
    }
   ],
   "source": [
    "EXAMPLES = ['3 May 1979', '5 April 09', '21th of August 2016', 'Tue 10 Jul 2007', 'Saturday May 9 2018', 'March 3 2001', 'March 3rd 2001', '1 March 2001']\n",
    "for example in EXAMPLES:\n",
    "    \n",
    "    source = string_to_int(example, Tx, human_vocab)\n",
    "    source = np.array(list(map(lambda x: to_categorical(x, num_classes=len(human_vocab)), source))).swapaxes(0,1)\n",
    "    prediction = model.predict([source, s0, c0])\n",
    "    prediction = np.argmax(prediction, axis = -1)\n",
    "    output = [inv_machine_vocab[int(i)] for i in prediction]\n",
    "    \n",
    "    print(\"source:\", example)\n",
    "    print(\"output:\", ''.join(output),\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 30, 37)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "s0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 30, 64)       17920       input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "repeat_vector_1 (RepeatVector)  (None, 30, 64)       0           s0[0][0]                         \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 30, 128)      0           bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[0][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[1][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[2][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[3][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[4][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[5][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[6][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[7][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[8][0]            \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 repeat_vector_1[9][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 30, 10)       1290        concatenate_1[0][0]              \n",
      "                                                                 concatenate_1[1][0]              \n",
      "                                                                 concatenate_1[2][0]              \n",
      "                                                                 concatenate_1[3][0]              \n",
      "                                                                 concatenate_1[4][0]              \n",
      "                                                                 concatenate_1[5][0]              \n",
      "                                                                 concatenate_1[6][0]              \n",
      "                                                                 concatenate_1[7][0]              \n",
      "                                                                 concatenate_1[8][0]              \n",
      "                                                                 concatenate_1[9][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 30, 1)        11          dense_1[0][0]                    \n",
      "                                                                 dense_1[1][0]                    \n",
      "                                                                 dense_1[2][0]                    \n",
      "                                                                 dense_1[3][0]                    \n",
      "                                                                 dense_1[4][0]                    \n",
      "                                                                 dense_1[5][0]                    \n",
      "                                                                 dense_1[6][0]                    \n",
      "                                                                 dense_1[7][0]                    \n",
      "                                                                 dense_1[8][0]                    \n",
      "                                                                 dense_1[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "attention_weights (Activation)  (None, 30, 1)        0           dense_2[0][0]                    \n",
      "                                                                 dense_2[1][0]                    \n",
      "                                                                 dense_2[2][0]                    \n",
      "                                                                 dense_2[3][0]                    \n",
      "                                                                 dense_2[4][0]                    \n",
      "                                                                 dense_2[5][0]                    \n",
      "                                                                 dense_2[6][0]                    \n",
      "                                                                 dense_2[7][0]                    \n",
      "                                                                 dense_2[8][0]                    \n",
      "                                                                 dense_2[9][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 1, 64)        0           attention_weights[0][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[1][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[2][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[3][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[4][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[5][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[6][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[7][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[8][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "                                                                 attention_weights[9][0]          \n",
      "                                                                 bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "c0 (InputLayer)                 (None, 64)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, 64), (None,  33024       dot_1[0][0]                      \n",
      "                                                                 s0[0][0]                         \n",
      "                                                                 c0[0][0]                         \n",
      "                                                                 dot_1[1][0]                      \n",
      "                                                                 lstm_1[0][0]                     \n",
      "                                                                 lstm_1[0][2]                     \n",
      "                                                                 dot_1[2][0]                      \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[1][2]                     \n",
      "                                                                 dot_1[3][0]                      \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[2][2]                     \n",
      "                                                                 dot_1[4][0]                      \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[3][2]                     \n",
      "                                                                 dot_1[5][0]                      \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[4][2]                     \n",
      "                                                                 dot_1[6][0]                      \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[5][2]                     \n",
      "                                                                 dot_1[7][0]                      \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[6][2]                     \n",
      "                                                                 dot_1[8][0]                      \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[7][2]                     \n",
      "                                                                 dot_1[9][0]                      \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[8][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 11)           715         lstm_1[0][0]                     \n",
      "                                                                 lstm_1[1][0]                     \n",
      "                                                                 lstm_1[2][0]                     \n",
      "                                                                 lstm_1[3][0]                     \n",
      "                                                                 lstm_1[4][0]                     \n",
      "                                                                 lstm_1[5][0]                     \n",
      "                                                                 lstm_1[6][0]                     \n",
      "                                                                 lstm_1[7][0]                     \n",
      "                                                                 lstm_1[8][0]                     \n",
      "                                                                 lstm_1[9][0]                     \n",
      "==================================================================================================\n",
      "Total params: 52,960\n",
      "Trainable params: 52,960\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAegAAAGpCAYAAABGVKXFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3debxdZXXw8d9KQiZAlFFlFkFAFEjCjKg4oXUAZ1SsivNQtaV16qu2b1Wsbd86tRaHUqviWLVSUBElQCBAwABhUhRQwIoMAglJSHLX+8feFw43Z+9z7r05N0/u/X0/n5ucc5797L3OPsM6e3pWZCaSJKks0zZ2AJIkaX0maEmSCmSCliSpQCZoSZIKZIKWJKlAJmhJkgo0Y2MH0GnbbbfNXXfdrWvbihUr2Hzzzcc036nUd1OL175lL7OfvmuGmi/VXL1yBbPmNPdddt1vG9seuc1c/veO+xrb9997l8a2lfctZ87cLRrbp0VjkzShbrrpRm6//fau78iiEvSuu+7GoouWdG278PxzOOzIp4xpvlOp76YWr33LXmY/fW+/d3Vj2zWXXcA+8w5vbN/z6L9obDvpjYfwgVMuamw/Z9EnG9uWLD6PBYc+qbF91mbTG9ukiXTEIQsa29zFLUlSgUzQkiQVaGAJOiK+FBG3RcSyQS1DkqTJapBb0KcCxwxw/pIkTVoDS9CZeS5w56DmL0nSZBaDrGYVEbsBp2fmfi3TvBF4I8AOO+ww/7Svf73rdMuXL2eLLZovm2gzlfpuavHat+xl9tN37brm75BV9y1ndsvlTlf+4ubGth233Zxbbl/R2L7/3js3tt23fDlzW2L2MiuV4qS/OIlLL11S5mVWmXkKcArA/PkLsulyjlIvMSmt76YWr33LXmY/fcdzmdXzT2q+zOojPS6z+t8LXtHY5mVWmgw8i1uSpAKZoCVJKtAgL7M6DbgQeFxE3BwRJw5qWZIkTTYDOwadmccPat6SJE127uKWJKlAJmhJkgq00S+zkrRp22J289fItGnR2h57zGtumzW3tf3qW+5tbFt1/7rW9gN3e3hjm1QKt6AlSSqQCVqSpAKZoCVJKtBAE3REvDMilkXEVRHxrkEuS5KkyWSQA5XsB7wBOBjYH3huROw5qOVJkjSZDHILeh9gcWbel5lrgYXAcQNcniRJk8bAyk1GxD7A94HDgJXA2cCSzHzHiOksN7kB+25q8dq37GX203eo5SukV9nHK264o7Ftx62mc8vd6xrb99qx+VKptavvY8asuY3tc2dZzUpl2CjlJjPzmoj4OHAWsBy4HFjbZTrLTW7AvptavPYte5n99F21pjmJXrr4POa3lH183mf/o7HtI8/Zig+ccXdj+9knP62x7c5fXcrWe8xvbPc6aG0KBnqSWGZ+MTPnZeZRwJ3ALwe5PEmSJouBjiQWEdtn5m0RsQvwQqrd3ZIkqYdBD/X5nYjYBlgDvC0z7xrw8iRJmhQGmqAzs/ngkyRJauRIYpIkFcgELUlSgSw3KWlcVq8ZamzLzPb231zV3Hb/ga3tu2zzysa25TdNY5dt5jS2S5sCt6AlSSpQXwk6InaNiKfXt+dExJaDDUuSpKmtZ4KOiDcA3wb+rX5oJ+B7/czcalaSJI1NP1vQbwOOAO4ByMxfAtv36mQ1K0mSxq6fBL06M+8fvhMRM4B+KmxYzUqSpDHqJ0EvjIj3A3Mi4hnAt4Af9NFvGXBURGwTEXOB5wA7jz1USZKmjp7lJiNiGnAi8EwggB8BX8g+6lRGxIlUu8iXA1cDKzPz3SOmsdzkBuy7qcVr37KX2U/fdS31JleuWM6czVvKTf7ilsa2HbeZyy133NfY/oQ9d2xsW3XfcmbPbV7ujOldq/tJE66t3GQ/CXpzYFVmrqvvTwdmZWbzJ6f7fD4K3JyZ/9I0zfz5C3LRRUu6tpVaaq+0vptavPYte5n99L37vjWNbVcuOZ8nLDiysX23p7+3se0jrzuQD3zp543t1//oo41tV192AfvOO7yxfZstZzW2SRPpiEMWNCbofnZxnw10XvE/B/hJPwuOiO3r/4erWZ3WTz9Jkqa6fkYSm52Zy4fvZOby+phyP6xmJUnSGPSToFdExLzMvAwgIuYDK/uZudWsJEkam34S9LuAb0XErfX9RwEvG1xIkiSpZ4LOzEsiYm/gcVRncV+bmc1nhUiSpHHrt5rVQcBu9fQHRgSZ+eWBRSVJ0hTXM0FHxH8CewBLgXX1wwmYoDWptV6CmO3trV0ThlquHR5Pv2i6vLdHvG3XMmfC2nXNJSNnbdZ8MUhEtLZfefrfNbb96orFXHn6ixrbH/vSTza2feSlu/L8k5vb7zrzrxrbpFL0swW9ANi3n4FJJEnShtHPddDLgEcOOhBJkvSgfragtwWujoiLgdXDD2bm89s6RcRs4FxgVr2cb2fmh8YRqyRJU0Y/CfrDY5z3auDoemCTzYDzI+LMzFw8xvlJkjRl9HOZ1cKI2BXYMzN/Uo8iNr2PfklVJANgs/rP49iSJPWh5zHoiHgD8G3g3+qHdgS+18/MI2J6RCwFbgPOysyLxhqoJElTST/VrJYCBwMXZeaB9WNXZuYT+l5IxMOB7wLvyMxlI9osN7kB+25q8Rbdt+Wj0atv26dqxfLlbD6GmPvp13SV1SDjbet73/LlzG3pu3Zdc+/VK5cza05z36tuuK2xbcdHzOSWu+5vbD9wzx0a26SJ1FZusp9j0Ksz8/6oL7CMiBmMcld1Zv4xIs4BjqE6K7yz7RTgFKjKTTaVtSu11F5pfTe1eEvu2/bjdfH5Czn0yCe39G1e7uJFCzn0iOa+4+nXdB10r3jbroO++IJzOfjwoxrb17b0vXTxecw/tHlI/tvvbU6iv7piMXs88dDG9mM//unGto+8dFc+8M2bGtvvOtPRilW+fi6zWhgR7wfmRMQzgG8BP+jVKSK2q7eciYg5wNOBa8cTrCRJU0U/Cfq9wB+AK4E3AWcAf91Hv0cBP4uIK4BLqI5Bnz7WQCVJmkr6OYt7CPh8/de3zLwCOHCMcUmSNKX1Mxb3DXQ55pyZjxlIRJIkqe+xuIfNBl4CbD2YcCRJEvRxDDoz7+j4uyUz/xk4egJikyRpyupnF/e8jrvTqLaotxxEMGuHkrvvW9O1bV1LG/Qopbcu+eOK5ss52vTq23a92dp1yV0tfdsubVm7Lrn93tWN7WPtN2dm8yBwQ0OwYvXa5r6bNfcdawnFfvq2zTWzfT22PZ91Q8k9K5vfU2tartFdO5TcuWKM78eh5M6W90XTtczrhtrfT1Xn7r17xTtjWtNSYSiTFavXNbbPbiknCc3PB2Cnrec0tv12RrS2t5WMvPD8c7yUSpu8fnZx/2PH7bXAjcBLBxKNJEkC+juL+6kTEYgkSXpQP7u4/7ytPTP/acOFI0mSoP+zuA8C/ru+/zyqOs+/HVRQkiRNdf0k6G2BeZl5L0BEfBj4Vma+fpCBSZI0lfUz1OcuQOepo/cDuw0kGkmSBPRXbvIDVGdtf5fqipfjgG9m5kc3SAAjyk1+5WundZ1u5YrlzNl8bKUBV963nDlzx1aSsFfftrW36r7lzB7jcsfat1e/aU3ljoD7Vixnbss6buk65hKKg+471PL+7vWeavtolPjajqdv22vbaz1F23uqR7nJlqu7NloZUmkitZWb7Jmg4YFroYdrxp2bmT/vd+ER8TbgDfXd52TmrU3T7n/g/PzxwsVd265ccj5PWHBk43LanseyJYvYb8ERfcU72r5ta69X37brd6+57AL2mXd4PyGOql/bddBLLzqfAw5pXsdt10GPtYRiP33b1vFFixZySEvftuugr7jkfJ54UPPzbbsO+upLF7Hv/Jb3Rcv7sddr1JSzrr7sAvbt9Z5oSJa94m27DrrXZ6/tOugli89jQUu5yVkt76mNVYZUmkhHHLJgXPWgAeYC92Tmv9dlJHfPzBv66ZiZnwU+2+dyJEkSfRyDjogPAe8B3lc/tBnwlUEGJUnSVNfPSWLHAc8HVgDUu6gHMtSnJEmq9JOg78/qgFoCRMTmgw1JkiT1k6C/GRH/Bjw8It4A/AT4/GDDkiRpautnLO5/iIhnAPcAewEfzMyzBhHM9GnB3IazjKdFcxtU1XqaRETr2aJtevVtq8I0LYKZ05t/A925qrky0VAmK+/vXkGo7ezvdUPJ8lXNZy63nZlcVXdq7jtrRvvvubZLmnpdLND2nFrnC6xdN9TY3laFqare1dze6/m2VWlqu/QI2i93m95wRnUEzGh5P0H7umq7pGnzWc3v8WkRre1tMU2L9jO1JTXr6yzuzDwrIi4DjgLuHGxIkiSp8advRJweEfvVtx8FLANeB/xnRLxrguKTJGlKattftntmLqtvvxY4KzOfBxxClaglSdKAtCXoNR23nwacAVAXzWg+6FeLiC9FxG0RsazXtJIk6aHaEvRvI+IdEXEcMA/4IUBEzKEarKSXU4Fjxh2hJElTUFuCPhF4PPAa4GWZ+cf68UOBf+8148w8F08okyRpTBrP4s7M24A3d3n8Z8DPBhmUJElTXV/VrMY884jdgNMzc7+WaR5SbvJrp32963S9ygq2PY1eZRTbDLLv2qHmQ/mrV65g1pzug7a1Pdf7V61g5uzmwd7arr9dtXI5s+c0xztjenPfQZaMbHuH9ipnuK7luu9ez7ftUuaNUfqxZ8lVmt8bvZbZdO019H592tbTxioZablJbSrayk32W81qYDLzFOAUgHnzF+RBhx3VdbpLLjyXpjZoH6jkssXnMa+l5F2bXn3bBipZevH5HHBwc5m+O1c0D1Ty6ysX85gnHNq1rW1QjxuXXcRu+x3S2N42aMQvl17Ingcc1ti+3ZYzG9suvuBcDj68+fVp+1HR67VtG3yjVznDO1esaWzr9XzbBiq56tJFPL6lfGObXn2bkmWvso/QvK56lT7dcnbzV0Gv17ZtoJKNVTLScpOaDPqpZrXep7rbY5IkacPpZyzuT/f52ENExGnAhcDjIuLmiDhxtMFJkjRVNe7XiojDgMOB7SLizzuaHgb0HFw3M48ff3iSJE1NbcegZwJb1NN01n++B3jxIIOSJGmqa7vMaiGwMCJOzcybJjAmSZKmvH7O4j41ItY7NTQzj97QwWQ2n6Hc1jZem7VcPhTR3j59s/ZSe3NbyvTNmTmnse2306ex4yO6t7eth1tnNPeD9kuWbpgebLNF85navUootrX36Mq0lst81n/3dbTRfolQ29nJ06ZFa/tdLWfZD2WyYnVzac7Va5ovoVs3lNy5vHneTeti7brkjpZ+0PxeHcr2MqT3tpQZXbNuiFvvWtXYvtXc5oEF1w0ld9/XfCb9w+a0fAUltF0G2uv9KG3q+knQJ3Xcng28CGj+NEuSpHHrmaAz89IRDy2KiIUDikeSJNFHgo6IrTvuTgPmA48cWESSJKmvXdyXUh26DKpd2zdQFdLoKSKOAT5JdVnWFzLz5DHGKUnSlNLPLu7dxzLjiJgOfBZ4BnAzcElE/HdmXj2W+UmSNJX0s4t7NvBW4EiqLenzgX/NzObTOisHA9dn5q/r+XwdeAFggpYkqYd+hvr8MlVd6E8DnwH2Af6zj347Ar/tuH9z/ZgkSeqhZ7nJiLg8M/fv9ViXfi8BnpWZr6/vnwAcnJnvGDHdQ8pNfvVr3ctNDrLsY9vllD1L7bUst1fJu7Y1P9byjYMs+7gp9m27dL5X+cZ1YywHCuMrCTqefk3v5V7xtunVt+069F7reHrLh69nycgBlbmUJtJ4y03+PCIOzczFABFxCLCoj343Azt33N8JuHXkRJ3lJg+ctyDnN5QOvHTxeTS1QXuy61Uysm0gkl6l9tq+nBafv5BDj3xyY3vbl/jiRQs59IjufdsGKulVurFtPS258FwWtPRte64XLVrIIQ3x9tKrb9uPyF6vz6qWAUN6lQNtG6ikrRwotA9UcvM1F7PTPgc3tjcNVPKbqy5il8c3lxKF5vdyr3jb3os3LFvM7vs1920bqKRXicy2gUp6fX7aBiqx3KQmg34S9CHAqyPiN/X9XYBrIuJKIDPziQ39LgH2jIjdgVuAlwOvGG/AkiRNBf0k6GPGMuPMXBsRbwd+RHWZ1Zcy86qxzEuSpKmmnwT9d5l5QucDEfGfIx/rJjPPAM4Ya3CSJE1V/ZzF/fjOOxExg2o0MUmSNCCNCToi3hcR9wJPjIh7IuLe+v7vge9PWISSJE1BbfWgPwZ8LCI+lpnvm4hgpgXMntm9POO0ac1tPec7DeaMsW8EzJjez46Gbp3HXoIxovls3tbSjAGbzRhbvBEws6Xv7/7YPDbN2nXJbfesbmz/xMJfN7YdOn0V3/7BNY3tM1rOsj+IVbz/zOsa2z/2nL0b26ZF+/tii9lzG9tunjGNnbdpbm/zh+un8dhHjv4SoN//YhqP2X5sl0qNJ95bZkxjl23H1nf6tGg9y7tVj8+PNNn1cwz6zIhY7zqWzDx3APFIkiT6S9B/2XF7NtUQnpcCRw8kIkmS1FexjOd13o+InYG/H1hEkiSpr7O4R7oZ2G9DByJJkh7UTzWrT/PgCJHTgAOAywcZlCRJU10/x6CXdNxeC5yWmf2MxS1Jksaon2pWs4HHUm1F/6qPOtCjC2BENavTvt69mtV4qtNMpb6DXOaatc3vlVUrlzN7TnPf/13efAnW5tzPCmY2trddaNOr745bzW5s61mpbEDVkkp8be0rbRxjqmZVjxj2UeB1wE1Uu7d3ioh/Bz6QmWs2RHCd1azmz1+QTRVoxlOdZir1HeQy266D/uXSC9nzgMMa27/Xeh30b1i8bpfG9vbroG/iEnZtbH/hEc3XQfeqotVWvWuyvbb2lcrTdpLYJ4Ctgd0zc35mHgjsATwc+Id+FxARb4uIpfXfo8cXriRJU0PbMejnAntlxz7wzLwnIt4CXAu8s58FZOZngc+OK0pJkqaYti3ozC4HqDNzHQ+e1S1JkgagLUFfHRGvHvlgRLyKagtakiQNSNsu7rcB/xURr6Ma2jOBg4A5wHETEJskSVNWWzWrW4BDIuJoqprQAZyZmWdPVHCSJE1V/YzF/VPgpxMQiwq37RbN1xvfMD1a27fevPmtNuP+YOvZze3nXfOHxrbH77iOy2+5s7G95Uopoke7+tM6lkK2t1tOUmo2xkLHkiRpkEzQkiQVyAQtSVKBBpqgI+KYiLguIq6PiPcOclmSJE0mA0vQETGdagSxZwP7AsdHxL6DWp4kSZPJILegDwauz8xfZ+b9wNeBFwxweZIkTRo9y02OecYRLwaOyczX1/dPAA7JzLePmM5ykxuw7yCX2fZW6VW68X/vbS43OTtXsypmNbbfu2ptY9s2m63ljjXNl2jttd3mjW0915XlJvvr2/K+2NTWsTTRxlRucgPotsBuY3tbbnID9h3kMtesHWpsu+TCcznosKMa2z9+zvWNbfvefwNXz9y9sf28XzVfB/2KHf/I1255eGP7D487vLFt8fkLOfTI5nKTbdfoTrbXdjx9237kb2rrWCrJIHdx3wzs3HF/J+DWAS5PkqRJY5AJ+hJgz4jYPSJmAi8H/nuAy5MkadIY2C7uzFwbEW8HfgRMB76UmVcNanmSJE0mgzwGTWaeAZwxyGVIkjQZOZKYJEkFMkFLklSgge7i1uSy2Yzm33MR7e3vP3rPxrbFi27l2COa27f58Bca217wmv25+BsLG9vXvOWwxrYE1qxrvkRo5oyxl0IcTwnGpqZMGBpqH7egqTUT1rX0bXumvZY7noqR41lP7TMe2zrWhrOxKolOphKmbkFLklQgE7QkSQUyQUuSVKBBl5t8Z0Qsi4irIuJdg1yWJEmTySDLTe4HvIGqqtX+wHMjovlMIEmS9IBBbkHvAyzOzPsycy2wEDhugMuTJGnSGGS5yX2A7wOHASuBs4ElmfmOEdNZbnID9i013vGUqlx63S2NbTtuM4db7ljZ2H7A43Yc83LbrtYYZAnGpq694m0zyL5tF7UU+34c01w1GhvtYqdN7CqrjVJuMjOviYiPA2cBy4HLgfUK+1pucsP2LTXetutoFy9ayKFHNJck/JP3vaex7SOv2Z8PnHp5Y/vvzzm+sW3JheeyoKVE5syW67oHWYKxqWuv9QTNieeiRQs5pKVv23dar+W2/ZDp9VzbDLKv10EPntdBj99ATxLLzC9m5rzMPAq4E/jlIJcnSdJkMdCRxCJi+8y8LSJ2AV5ItbtbkiT1MOihPr8TEdsAa4C3ZeZdA16eJEmTwqDLTT5pkPOXJGmyciQxSZIKZIKWJKlAA7sOeiwi4g/ATQ3N2wK3j3HWU6nvphavfcte5lTsK02kXTNzu24NRSXoNhGxJDMX2Le8Zdp3YvpuavFuqn2lUriLW5KkApmgJUkq0KaUoE+xb7HLtO/E9N3U4t1U+0pF2GSOQUuSNJUUvwVdDxMqSdKUUnSCjojnAGdHRHPNwEkkInaIyVSKZZLyNZI0EYpN0BHxLOAfgBMy85aImNBYx/slHBFbjXL6HYG/Bo7fGAkgInaNiNkTuLzHRcRhEbFZREwfRb89I2JBREwfTb8NISJ2qseW32kCljUzIvatbz8tIh416GV2iWFM63esr9F4XtuIeHxEPLl+faRJYdDFMsYkIp4JfBk4j6pMJZk5FBGRozxoHhFHAvsCnx9l30cDt0TEjMxcr451j2W+FdgyIv41M+/ps9utwKXAgcDqiPivMTzXOZm5cjR96n7bAycBH6vjGKiIeCHwUeCW+m9JRJzaa11FxLHA3wDXAzcD10XEf2TmigmI+QXAe4HfA4+KiDOBj2bm/aOYxz6ZeU2fk+8C/HNE/B7YGnj1aGMeq4jYKzN/kZnrImJ6Zq4bRd8xvUbjeW0j4tnAx4FfA5tFxImZ+b/9xiyVqrgt6Ih4GvAZ4M+BC4DX1UmWzMx+ty47trgfAzwReNUo+r4d+FxEnAy8NSJmjSL+NwF/CnwtM++JiJ4/gjp+eAwBewPvAV4wmi3pOua/j4iPjXbrnWrEpV2BPxtlv1GLiM2AlwEnZubTgO8DOwN/FREPa+m3DfAm4PjMfBFwOfBa4N0RseWAY34q8Ang7cBrgBOAY4AP9btnJyLeAnwiInboZ/rMvB64AngBcGZm3lFvWQ5070pEPBdYGhFfq+NY1+/W7Fhfo/G8thHxFOCTwOsz81jgfmC/fuKVSldcggbuAV6TmV8F/oeqVOWfRMQRMKokvUf9/1eotsQPBF7dq2/9S/6lVF/ChwB7ZebqfgKPiDnAs4EPAvfVX8qfrf9vVD+nVwLvAD5A9cPkqcCL+nmu9Rb7S4CTgdcBn46IPfvo9+h6a2mIKvnsEBF79+q3ATwMGI7vu8DpwEzgFS3Pdy2wBfBIgMz8EtWwsNsBzx1otHA48KnMvBRYlZm/oPqR8Wzg/b06R8TzgTdTlVz9/SiW+zngrVQ/Ul+Zmevq98oWo38KvUXE5lTvg3cB90fEV2BUSXqsr9F4XtvfA2/KzIsj4pFUn9m3R8S/RcSLN8bhImlDKS5BZ+YlmXlBREzLzOuodnWvAZ4bEYfX07Tu+o3qzO+zIuKEOvl8B/g58ErgtT0+tFsB/wwcWy/3z+t57tVH7CuBM6h2FX+Jaqv0KmC/iJjZo/vjgG9m5hXAX1Lt6nsH8JK2eOutznnAy4EXUT1PgE+1Jen6y/gvqfYUvBHYElgN7Fi3D+SLLTPXAP8EvDAinlS/PucDS4EjW/rdDXyV6vU7ISI+AqwCrgaeMYhYO9bBTlRjO0N1+GF6Zt5EtTX99IjYvsf6ejTwjcy8qd6D0JfMvD4zvwJ8iGoPw5/Uh3/+qp89M6NV705+HfA1qkMeszuTdB/9x/Qajee1zcxrMvNn9d0TgX+pt6QXU/1o3baxs1S6zCz+j2pr60PAp4BD+uzzPOAyqt1mw4+dAfwjsFVLvycDvwLO63jsz4C/BzbrY7mzgYOArev7xwM/A+b26Hcs8D3g8R2PnQ98BNiyR99ZwP7Az+r7QbXb+m+BmT1inQd8g2rL/ffAJcCOA349Z1NtqZ0CHNXx+E+BA1r6bUX1I+vfgf/X8fjpwMMGGO/TgJ8A8+v704DNqBLvd4DNe/R/NnAm8LiOx04Ajh1FDMdQ7fJeAuw7yNenY5nb1M/vK/X9ecDePfqM6TUaxGtbf97nTcS68s+/QfwVeZLYSJn5y4j4BnAc1Ykg/fT5QUSsA06udz3fSXWM9x+y+sXe5FKq46JD9fGtXaiOKf9pVlt/vZa7CrgkIqZFxIlUuwuPz8z7enQ9hyqxHx8RPwWGY/50Zt7bY5mrI+I+YEZEPIHqmO4PgS9ky0lMdayX1VvQs6gSzwH1c76l49j4BpWZqyLiq0AC76t3q68GdgB+19LvbuCrEXFaVlveRMSrqU6i6vtEpjFYTPVj6WURQVa7uofqcyO2pkrWbRYBRwB/GhEXUO2t+DOqH299ycwfRsSl9e0/jOE5jFpWx73fRHXs/FpgOtWhl7Y+Y3qNxvvajnyvRsSLqN5PAz/pURqUTWoksYjYrJ8kOaLPk6nODr0PeG9Wu5B79XkU8Pz67w7gE5l55SiXO5fqOOXi7PPM3Yh4NPDC+m8t8Bf9LjeqE9neBTyd6ovppZl57WhirufzAaryZ28cbd8xLGsmVeJ6E9UuzU9m5s/bez2k/+uodsW+bLSvz2hFdRnc64GjgQupTkZ6MdWPr8v76P8oqhO+ng/cDXysn/diCSLi3VQnLj5jDJ+DMb1G4+g3C3gV1aGpl2XmstHEK5Vkk0rQY1Uny8xRXoI0fLxwtD8KOvqPaQu0Pj4cmbl8lP02ozrRZigzbxll38jMjIiXU51Be+xo19dY1Scg5fCW0yj67Up12OH6wUS23vLmAAuAZ1EdQjgzq/MkRjOPmQBtezZKEhGPAL5J9WNx1D8oxvoajaPfZlTHrX812tdGKs2USNDqT32i03OBG9zy0LCImF0fDpE0gUzQkiQVqLjLrCRJkglakqQimaAlSSqQCVqSpAKZoCVJKpAJWppAETGqa9v7nOduEfGKhrZpEfGpiFgWEVdGxCURsfuGjkHShrdJDPUpqdVuwCuoilyM9DKqMcOfmFVN9UQQ2MUAABVaSURBVJ2AgdfPljR+bkFLG0FEPCUizomIb0fEtRHx1eGKWBFxY0R8PCIurv8eWz9+akS8uGMew1vjJwNPioil9bCcnR4F/G54lLbMvDkz76r7PzMiLoyIyyLiW1GXsYyIY+qYzq+3vk+vH/9wRJzUsfxlEbFbfftVdaxLoyr1OH04xoj4SERcHhGLo66HHRE7RMR368cvj7pSXdN8pKnIBC1tPAdSjZ++L/AYqnHJh92TmQcDn6Eqf9rmvVTV1w7IzP83ou2bwPPqhPePEXEgQERsC/w18PTMnEdVJevPI2I28HmqanBPoq7R3CYi9qHaUj8iMw+gKm7xyrp5c6rx6PcHzgXeUD/+KWBh/fg84Koe85GmHHdxSxvPxZl5M0BELKXaVX1+3XZax/8jk27fMvPmiHgcVZGPo4GzI+IlVNXS9gUW1RvuM6mKgOxNNdTrL+u4vgL0KpzyNGA+VRU36nnfVrfdT1UyEqpKccP1nY8GXl3HuA64OyJOaJmPNOWYoKWNZ3XH7XU89POYXW6vpd7rVe8On9nPQjJzNVU96jMj4vdUtcd/DJyVmQ8peRkRB4xYdqcHll+bPdwN+I/MfF+XPms6CsaMfI4jtc1HmnLcxS2V6WUd/19Y376RagsTqtKVw3Wo76WqMb2eiJhXlzElIqYBTwRuoqpxfUTH8e25EbEXcC2we0TsUc+iM4HfSLU7moiYBwyfDX428OKI2L5u27quRtXmbOAt9fTTI+JhY5yPNGmZoKUyzYqIi4B3AsMnfn0eeHJEXAwcwoNnY18BrK1Pthp5ktj2wA8iYtnwdMBnMvMPwGuA0yLiCqqEvXddteqNwP9ExPlUyXzYd4Ct693xbwF+AZCZV1Mdz/5xPa+zqE5Oa/NO4KkRcSXVru/Hj3E+0qRlNSupMBFxI7AgM28vIJanACdl5nM3dizSVOMWtCRJBXILWpKkArkFLUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFM0JIkFcgELUlSgUzQkiQVyAQtSVKBTNCSJBXIBC1JUoFmbOwANlXPfNYxefvtt/ecLh/4p6GtqRHI5qb1e7Yuo2GibO1a0LKysd96j2dzHN3m0e31aeoxMq6R8+ve3jC3Pvp3jwIyW9f0eu+b7uuo+xrt3bd7z9Z+2eM1aHw/dVlJnfPo8sR6ft66rYyGttFO/5Cp2j68D3wW2lf2Q9pHuY46P3DdXsO26RsXuF6/bh/qkTF36dP2ZdKx/Fz5hx9l5jFdgp0yTNBjdMftt7No8ZKHfECS6j2cIz4c2fGB7HyPd06b+dD38/C0nZ+Xzv4Pzveh/TuX1flZ6BVX12lH8bw25LKGOpLAcPvQeuulemBo5DpMGHrIOnlwnQ2NWKeZyRAPfplmx2PD7Z3TPzSu4b4dbVn9/0BcI2IZ6mgfvp8d0w+NfF4d8x55v5r3yGV3xDbyfufzzAf7dD7PzueYD3keD522M+6k+7w6n+dwn87Xr+u8GuLKEfNa/3779P1Nu37foaH+Y2G9ea3f1tm+IaYfy7yqwIc6PpBDDz7W9X6X2019h4bb+5y+qb2+vWrpZ7dlinMXtyRJBTJBS5JUIBO0JEkFMkFLklQgE7QkSQUyQUuSVCATtCRJBTJBS5JUIBO0JEkFMkFLklQgE7QkSQUyQUuSVCATtCRJBTJBS5JUIBO0JEkFMkFLklQgE7QkSQWKzNzYMWySIuKHwLYbO44W2wK3b+wgWhjf2JUcGxjfeBlf5fbMPGYCllMsE/QkFRFLMnPBxo6jifGNXcmxgfGNl/FpmLu4JUkqkAlakqQCmaAnr1M2dgA9GN/YlRwbGN94GZ8Aj0FLklQkt6AlSSqQCXoTFhHHRMR1EXF9RLy3S/veEXFhRKyOiJMKjO+VEXFF/XdBROxfWHwvqGNbGhFLIuLIkuLrmO6giFgXES8uKb6IeEpE3F2vv6UR8cGS4uuIcWlEXBURC0uKLyL+smPdLatf460Lim+riPhBRFxer7/XTlRsU0Zm+rcJ/gHTgV8BjwFmApcD+46YZnvgIOAjwEkFxnc48Ij69rOBiwqLbwsePAz0RODakuLrmO6nwBnAi0uKD3gKcPpEvu9GGd/DgauBXer725cU34jpnwf8tKT4gPcDH69vbwfcCczcGK/3ZP1zC3rTdTBwfWb+OjPvB74OvKBzgsy8LTMvAdYUGt8FmXlXfXcxsFNh8S3P+tsH2ByYyBM2esZXewfwHeC2CYwN+o9vY+knvlcA/5WZv4Hq81JYfJ2OB06bkMgq/cSXwJYREVQ/Zu8E1k5gjJOeCXrTtSPw2477N9ePlWK08Z0InDnQiB6qr/gi4riIuBb4H+B1ExQb9BFfROwIHAd8bgLjGtbv63tYvQv0zIh4/MSEBvQX317AIyLinIi4NCJePWHRjeLzERFzgWOofohNlH7i+wywD3ArcCXwzswcmpjwpoYZGzsAjVl0eaykU/L7ji8inkqVoCfyGG9f8WXmd4HvRsRRwP8Fnj7owGr9xPfPwHsyc121ETOh+onvMmDXzFweEc8BvgfsOfDIKv3ENwOYDzwNmANcGBGLM/MXgw6O0X1+nwcsysw7BxjPSP3E9yxgKXA0sAdwVkScl5n3DDq4qcIt6E3XzcDOHfd3ovolW4q+4ouIJwJfAF6QmXdMUGwwyvWXmecCe0TERI2/3k98C4CvR8SNwIuBf4mIYycmvN7xZeY9mbm8vn0GsFlh6+9m4IeZuSIzbwfOBSbqRMXRvP9ezsTu3ob+4nst1SGCzMzrgRuAvScovinBBL3pugTYMyJ2j4iZVB/i/97IMXXqGV9E7AL8F3DCBG21jDa+x9bH14iIeVQny0zUj4ie8WXm7pm5W2buBnwbeGtmfq+U+CLikR3r72Cq75ti1h/wfeBJETGj3o18CHBNQfEREVsBT65jnUj9xPcbqr0PRMQOwOOAX09olJOcu7g3UZm5NiLeDvyI6ozLL2XmVRHx5rr9cxHxSGAJ8DBgKCLeRXUm5sB3QfUTH/BBYBuqLT+AtTlBg/D3Gd+LgFdHxBpgJfCyjpPGSohvo+kzvhcDb4mItVTr7+Ulrb/MvCaqqnRXAEPAFzJzWSnx1ZMeB/w4M1dMRFyjjO//AqdGxJVUu8TfU++J0AbiSGKSJBXIXdySJBXIBC1JUoFM0JIkFcgErQfUg3JkROzd8dhuEdF64kw/02xIEfGaiPjMBppXRMRPI+Jh9f11HWMff6s+u3c081s+yulPjS5jaEfEgoj4VH37gecbEW8eHlCjfvzRo1neaEU1VvXh45zH+8fQ5yURcU1E/GzE47tFxCs67o/rvVCv/6fUg5XsNob+e9fvl59HxPyIeOtYYxnFMj9cP+9TI+Ip9WNfj4iJusZcE8QErU7HA+dTXVIxVTwHuLzjzPaVmXlAZu4H3A+8uXPiOqEP/HOTmUsy88+6PP65zPxyffc1wEATNNV42uNK0FRjNo/WiVSXjT11xOO7UQ3RWYpjge9n5oFUl5ANPEE3+FfgrzbSsjUgJmgBEBFbAEdQfTF2TdD1r/bvR8QPo6py86GO5ukR8fmoqtr8OCLm1H3eEBGXRDXc43dGbpFGxLSIuDEiHt7x2PURsUNEPC8iLqq3Tn5SX2s5MqaHbIF2bsFGVQ3okqgqUv1Nw1N/Jc3XmJ4HPLbearsmIv6FanSsnSPi+Ii4st7S/viImP4xIi6LiLMjYrs+1sPTI+K8iPhFRDy3nv4pEXF6l+f74Yg4qX7OC4Cv1ltwfxIR3+2Y7hkR8V9d+j+tXp9XRsSXImJW/fiNUQ8iUm+9D29Rvhl4d72MJ9Xr+3Nd4n3IlmxEnF4/h5OBOXX/r3aJZ731GFXVqyOBz0XEJ0Z0OZnq2uWlEfHu+rFH1+/JX0bE33fM+5lRVXO7LKq9IVuMXD5wN9UPsTuBdRExvX6Oy+q43l3P64CIWFy/l74bEY+IanS0dwGvj2pL/2SqwWyWRsQn6ue/MCK+Wa+rk6Oq4HZxPe896nl3fZ9HxKfqdUFEPCsizo3qx+FyqsvWhmOH6r369Ijw0tnJZGNX6/CvjD/gVcAX69sXAPPq27sBy+rbrwF+R3Xt8hxgGVWS2I1qkPwD6um+Cbyqvr1NxzL+DnhHl2V/EnhtffsQ4Cf17Ufw4KWArwf+sSOOz9S3T6WjihOwvP7/mcApVNdnTgNOB47qsuybgC279J9BlbjfUj+/IeDQuu3RVIM0bFdP91Pg2LotgVfWtz/YEWfX9VDH/8M6xj2pRnCaTUclqBHP98PUlcmAc4AF9e0ArgW2q+9/DXjeiOc6m2p85b3q+18G3lXfvhHYtr69ADhn5PJ6xPtAjPV0pwNP6VynXdZ923p84LmN6PPAeulYN78GtqrjuIlqBKxtqUYG27ye7j3AB/v4HMwHzuq4//D6/yuAJ9e3/xb45y6vx27Un5WOWP8IPAqYBdwC/E3d9s6OeTS9z+cCVwFPBa4D9ugR+1nA/I39XeLfhvtzC1rDjqeqWEP9//EN052VmXdk5kqqUcCGx8++ITOX1rcvpfqyAtiv3tq6kmprtVvBhG8AL6tvv7y+D9Xwgj+q+/5lQ98mz6z/fk611bs33ceB3joz7+24PycillIN8PIb4Iv14zdl5uL69kFUCewPmbkW+CpwVN021BH/V3hw/bSth29m5lBm/pIq2Yx6uMSsvqH/E3hVvTfiMNYvPvI4qtdpeNS2/+iIezTGHW+tbT2OxtmZeXdmrqIqH7krcCiwL7Cofj3/tH68l18Dj4mIT0fEMcA9UY3m9fDMHK4XPZr1dklm/i4zV1OVb/xx/fiVPPgZ6fo+z8z7gDdQJd7PZOaveizrNgZ/yEMTyN0hIiK2oRrwfr+ISKqRgzIiuh3TGjmyzfD91R2PraPawoZqi+vYzLw8Il5DtVUx0oVUu5K3ozqm93f1458G/ikz/zuqk2E+3KXvWupDNRERVMNxQrVF+bHM/LcufR7SPyKm5YNVeFZm5gGdE1SzpXMkp9FUphheP6fSvB6a1ulo/TvwA2AV8K066XVqi/uB9Ui1JdqmW7yd/fuZR694RmPke29GPe+zMrPph2ZXmXlXROxPVQjibcBLgXe39+o7tqGO+0M8+P3b9j5/AtWx7X4S72yqXd+aJNyCFlRDMn45M3fNamznnakGvu9WXeoZEbF1VMeYjwUW9Zj3lsDvImIzqi3H9dRbf98F/gm4Jh8smrEV1W5BqLaAurmRarckVPVqN6tv/wh43fBxx4jYMSK279L/Oqqi9KNxEfDkiNg2IqZT7W0Y3rqaRrU+oTqZ6fz6dtt6eElUx+L3qGO5rs847q3nC0Bm3kpV0OCvqX4QjHQtsFtEPLa+f0JH3Dfy4Hp8UdMyWuK9ETigfnxnqnrCw9bUz3uktvXYpFs83SwGjhh+rhExNyL26tWpPg4/LTO/A/wfqkM9dwN3RcST6sk619tYYhup6/s8InYF/gI4EHh2RBzSYz57Ue0S1yRhghZUX4zfHfHYd+h+tuz5VLtSlwLfycwlPeb9f6i+iM+iShBNvkF1HPwbHY99GPhWRJwHNI3x+3mqL/mLqY5frwDIzB9THYe9sN51+G26f3n+D9236htl5u+A9wE/Ay4HLsvM4RPNVgCPj4hLqfZK/G39eNt6uI7qC/9M4M31rtp+nEp1ItXS+gcTVLuJf5uZV3eJexVVBaJv1etkiAdrSf8N8Ml6Xa/r6PYD4Ljhk8Ra4l1E9aPuSuAfqA4rDDsFuGLkSWI91mOTK6j2elzecZLYejLzD1THp0+LiCuoEnY/u+J3BM6pd4ufWscHVeL8RD2vA3jwde1c5h1Uu9SXdTm5rc2HGfE+r/cGfZHq+PatVCdvfiEiuu6ZqE8sW1mvU00SjsWtvtW7Zhdk5ts3diwbSkQ8imrvwTM2diwbQlRnUv88M7/Yc+Kxzf9UqpO0vj2I+Wts6h8r9wzqddfG4Ra0prR6i+PzUQ9Usimrt9qfSHVymqaWP1KdvKZJxC1oSZIK5Ba0JEkFMkFLklQgE7QkSQUyQUuSVCATtCRJBTJBS5JUoP8PhSI/e2Z/7qoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x612 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "attention_map = plot_attention_map(model, human_vocab, inv_machine_vocab, \"Tuesday 09 Oct 1993\", num = 7, n_s = 64);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
